{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Julia to manage text files\n",
    "This is a short demo on how to pull files from azure blob storage and decode them to produce a dictionary.   Some of the files are in python pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <azure.storage.blob.blockblobservice.BlockBlobService object at 0x7f8e552f75f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport azure.storage.blob as asb\n",
    "bbs = asb.BlockBlobService(\"dbgannonstorage\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <azure.storage.blob.models.Blob object at 0x7f8e56f82278>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport io\n",
    "\n",
    "output_stream = io.BytesIO()\n",
    "fblob = bbs[:get_blob_to_path](\"algorithmiagensim\", \"data_collection.p\", file_path=\"/home/jovyan/data_collection.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <azure.storage.common.models.ListGenerator object at 0x7f8e56f822e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=bbs[:list_blobs](\"algorithmiagensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_collection.p\n",
      "gensim_model\n",
      "topicdict\n"
     ]
    }
   ],
   "source": [
    "for i in l\n",
    "    println(i[:name])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <azure.storage.blob.models.Blob object at 0x7f8e54c5a1d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport io\n",
    "\n",
    "output_stream = io.BytesIO()\n",
    "fblob = bbs[:get_blob_to_path](\"algorithmiagensim\", \"data_collection.p\", file_path=\"/home/jovyan/data_collection.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyimport pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IOStream(<file /home/jovyan/data_collection.p>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"/home/jovyan/data_collection.p\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 9 entries:\n",
       "  \"test_titles\"     => [\"Hojman Symmetry in \\$f(T)\\$ Theory [gr-qc]\", \"Sketchin…\n",
       "  \"train_abstracts\" => [\"It is shown that holographic cosmology implies an evol…\n",
       "  \"sites\"           => [\"cs.RO\", \"math.FA\", \"physics.soc-ph\", \"math.ST\", \"gr-qc…\n",
       "  \"abstracts\"       => [\"Deep convolutional neural networks (CNN) have recently…\n",
       "  \"test_abstracts\"  => [\"In this work, we consider Hojman symmetry in \\$f(T)\\$ …\n",
       "  \"train_titles\"    => [\"Accelerated expansion from cosmological holography [gr…\n",
       "  \"titles\"          => [\"Convolutional Neural Network-Based Image Representatio…\n",
       "  \"train_sites\"     => [\"gr-qc\", \"gr-qc\", \"astro-ph.GA\", \"astro-ph.CO\", \"cs.LG\"…\n",
       "  \"test_sites\"      => [\"gr-qc\", \"cs.LG\", \"cond-mat.soft\", \"cs.CV\", \"physics.pl…"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict = pickle.loads(pybytes(read(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = datadict[\"titles\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6761"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6761-element Array{String,1}:\n",
       " \"Deep convolutional neural networks (CNN) have recently been shown in many computer vision and pattern recog- nition applications to outperform by a significant margin state- of-the-art solutions that use traditional hand-crafted features. However, this impressive performance is yet to be fully exploited in robotics. In this paper, we focus one specific problem that can benefit from the recent development of the CNN technology, i.e., we focus on using a pre-trained CNN model as a method of generating an image representation appropriate for visual loop closure detection in SLAM (simultaneous localization and mapping). We perform a comprehensive evaluation of the outputs at the intermediate layers of a CNN as image descriptors, in comparison with state-of-the-art image descriptors, in terms of their ability to match images for detecting loop closures. The main conclusions of our study include: (a) CNN-based image representations perform comparably to state-of-the-art hand- crafted competitors in environments without significant lighting change, (b) they outperform state-of-the-art competitors when lighting changes significantly, and (c) they are also significantly faster to extract than the state-of-the-art hand-crafted features even on a conventional CPU and are two orders of magnitude faster on an entry-level GPU.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       " \"In this paper, we propose to study spectral measures on local fields. Some basic results are presented, including the stability of Bessel sequences under perturbation, the Landau theorem on Beurling density, the law of pure type of spectral measures, the boundedness of the Radon-Nikodym derivative of absolutely continuous \\$F\\$-spectral measures etc.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       " \"can evolve simultaneously. For the information-driven adaptive process, susceptible (infected) individuals who have abilities to recognize the disease would break the links of their infected (susceptible) neighbors to prevent the epidemic from further spreading. Simulation results and numerical analyses based on the pairwise approach indicate that the information-driven adaptive process can not only slow down the speed of epidemic spreading, but can also diminish the epidemic prevalence at the final state significantly. In addition, the disease spreading and information diffusion pattern on the lattice give a visual representation about how the disease is trapped into an isolated field with the information-driven adaptive process. Furthermore, we perform the local bifurcation analysis on four types of dynamical regions, including healthy, oscillatory, bistable and endemic, to understand the evolution of the observed dynamical behaviors. This work may shed some lights on understanding how information affects human activities on responding to epidemic spreading.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " \"In this work, we present a method to generate probability distributions and classes of probability distributions, which broadens a process of probability distribution construction. In this method, distribution classes are built from pre-defined monotonic functions and from known distributions. With the use of this method, we can obtain different classes of probability distributions described in literature. Beside these results, we could obtain results on the support and nature of the generated distributions.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       " \"In this work, we consider Hojman symmetry in \\$f(T)\\$ theory. Unlike Noether conservation theorem, the symmetry vectors and the corresponding conserved quantities in Hojman conservation theorem can be obtained by using directly the equations of motion, rather than Lagrangian or Hamiltonian. We find that Hojman symmetry can exist in \\$f(T)\\$ theory, and the corresponding exact cosmological solutions are obtained. We find that the functional form of \\$f(T)\\$ is restricted to be the power-law or hypergeometric type, while the universe experiences a power-law or hyperbolic expansion. These results are different from the ones obtained by using Noether symmetry in \\$f(T)\\$ theory.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       " \"We look at the question posed by Parker {\\\\it et al.} about the effect of UV regularisation on the power spectrum for inflation. Focusing on the slow-roll \\$k\\$-inflation, we show that up to second order in the Hubble and sound flow parameters, the adiabatic regularisation of such model leads to no difference in the power spectrum apart from certain cases that violate near scale invariant power spectra. Furthermore, extending to non-minimal \\$k\\$-inflation, we establish the equivalence of the subtraction terms in the adiabatic regularisation of the power spectrum in Jordan and Einstein frames.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       " \"Defining the extent of epistasis - the non-independence of the effects of mutations - is essential for understanding the relationship of genotype, phenotype, and fitness in biological systems. The applications cover many areas of biological research, including biochemistry, genomics, protein and systems engineering, medicine, and evolutionary biology. However, the quantitative definitions of epistasis vary among fields, and its analysis beyond just pairwise effects remains obscure in general. Here, we show that different definitions of epistasis are versions of a single mathematical formalism - the weighted Walsh-Hadamard transform. We discuss that one of the definitions, the backgound-averaged epistasis, is the most informative when the goal is to uncover the general epistatic structure of a biological system, a description that can be rather different from the local epistatic structure of specific model systems. Key issues are the choice of effective ensembles for averaging and to practically contend with the vast combinatorial complexity of mutations. In this regard, we discuss possible approaches for optimally learning the epistatic structure of biological systems.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       " \"We study sequential change-point detection using sketches (or linear projections) of the high-dimensional data vectors, and present a new sketching procedure, which is based on the generalized likelihood ratio statistic. We derive theoretical approximations to two fundamental performance metrics for the sketching procedures: the average run length (ARL) and the expected detection delay (EDD), and these approximations are shown to be highly accurate by numerical simulations. We also analyze the ratio of EDD between the sketching procedure and a procedure using the original data, when the sketching matrix \\$A\\$ is a random Gaussian matrix and a sparse 0-1 matrix (in particular, an expander graph), respectively. Finally, numerical examples demonstrate that the sketching procedure can approach the performance of the procedure using the original data, even when the post-change mean vector is not sparse.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       " \"The resurgence of vector-borne diseases is an increasing public health concern, and there is a need for a better understanding of their dynamics. For a number of diseases, e.g. dengue and chikungunya, this resurgence occurs mostly in urban environments, which are naturally very heterogeneous, particularly due to population circulation. In this scenario, there is an increasing interest in both multi-patch and multi-group models for such diseases. In this work, we study the dynamics of a vector borne disease within a class of multi-group models that extends the classical Bailey-Dietz model. This class includes many of the proposed models in the literature, and it can accommodate various functional forms of the infection force. For such models, the vector-host/host-vector contact network topology gives rise to a bipartite graph which has different properties from the ones usually found in directly transmitted diseases. Under the assumption that the contact network is strongly connected, we can define the basic reproductive number \\$\\\\mathcal{R}_0\\$ and show that this system has only two equilibria: the so called disease free equilibrium (DFE); and a unique interior equilibrium---usually termed the endemic equilibrium (EE)---that exists if, and only if, \\$\\\\mathcal{R}_0&gt;1\\$. We also show that, if \\$\\\\mathcal{R}_0\\\\leq1\\$, then the DFE equilibrium is globally asymptotically stable, while when \\$\\\\mathcal{R}_0&gt;1\\$, we have that the EE is globally asymptotically stable.\"                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " \"We characterize the expected statistical errors with which the parameters of black-hole binaries can be measured from gravitational-wave (GW) observations of their inspiral, merger and ringdown by a network of second-generation ground-based GW observatories. We simulate a population of black-hole binaries with uniform distribution of component masses in the interval \\$(3,80)~M_\\\\odot\\$, distributed uniformly in comoving volume, with isotropic orientations. From signals producing signal-to-noise ratio \\$\\\\geq 5\\$ in at least two detectors, we estimate the posterior distributions of the binary parameters using the Bayesian parameter estimation code LALInference. The GW signals will be redshifted due to the cosmological expansion and we measure only the \\\"redshifted\\\" masses. By assuming a cosmology, it is possible to estimate the gravitational masses by inferring the redshift from the measured posterior of the luminosity distance. We find that the measurement of the gravitational masses will be in general dominated by the error in measuring the luminosity distance. In spite of this, the component masses of more than \\$50\\\\%\\$ of the population can be measured with accuracy better than \\$\\\\sim 25\\\\%\\$ using the Advanced LIGO-Virgo network. Additionally, the mass of the final black hole can be measured with median accuracy \\$\\\\sim 18\\\\%\\$. Spin of the final black hole can be measured with median accuracy \\$\\\\sim 5\\\\% ~(17\\\\%)\\$ for binaries with non-spinning (aligned-spin) black holes. Additional detectors in Japan and India significantly improve the accuracy of sky localization, and moderately improve the estimation of luminosity distance, and hence, that of all mass parameters. We discuss the implication of these results on the observational evidence of intermediate-mass black holes and the estimation of cosmological parameters using GW observations.\"\n",
       " \"We investigate similarities in the micro-structural dynamics between externally driven and actively driven nematics. Walls, lines of strong deformations in the director field, and topological defects are characteristic features of an active nematic. Similar structures form in driven passive nematics when there are inhomogeneities in imposed velocity gradients due to non-linear flow fields or geometrical constraints. Specifically, pressure driven flow of a tumbling passive nematic in an expanding-contracting channel produces walls and defects similar to those seen in active nematics. We also study the response of active nematics to external driving, confirming that imposed shear suppresses the hydrodynamic instabilities. We show that shear fields can lead to wall alignments and the localisation of active turbulence.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       " \"Morse Theory on Banach spaces would be a useful tool in nonlinear analysis but its development is hindered by many technical problems. In this paper we present an approach based on a new notion of generalized functions called \\\\textquotedblleft ultrafunctions\\\\textquotedblright\\\\ which solves some of the technical questions involved.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       " \"A short inflationary phase may not erase all traces of the primordial universe. Associated observables include both spatial curvature and \\\"anomalies\\\" in the microwave background or large scale structure. The present curvature \\$\\\\Omega_{K,0}\\$ reflects the initial curvature, \\$\\\\Omega_{K,\\\\mathrm{start}}\\$, and the angular size of anomalies depends on \\$k_\\\\mathrm{start}\\$, the comoving horizon size at the onset of inflation. We estimate posteriors for \\$\\\\Omega_{K,\\\\mathrm{start}}\\$ and \\$k_\\\\mathrm{start}\\$ using current data and simulations, and show that if either quantity is measured to have a non-zero value, both are likely to be observable. Mappings from \\$\\\\Omega_{K,\\\\mathrm{start}}\\$ and \\$k_\\\\mathrm{start}\\$ to present-day observables depend strongly on the primordial equation of state; \\$\\\\Omega_{K,0}\\$ spans ten orders of magnitude for a given \\$\\\\Omega_{K,\\\\mathrm{start}}\\$ while a simple and general relationship connects \\$\\\\Omega_{K,0}\\$ and \\$k_\\\\mathrm{start}\\$. We show that current bounds on \\$\\\\Omega_{K,0}\\$ imply that if \\$k_\\\\mathrm{start}\\$ is measurable, the curvature was already small when inflation began. Finally, since the energy density changes slowly during inflation, primordial gravitational wave constraints require that a short inflationary phase is preceded by a nontrivial pre-inflationary phase with critical implications for the expected value of \\$\\\\Omega_{K,\\\\mathrm{start}}\\$.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       " ⋮                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       " \"In recent years, analyzing task-based fMRI (tfMRI) data has become an essential tool for understanding brain function and networks. However, due to the sheer size of tfMRI data, its intrinsic complex structure, and lack of ground truth of underlying neural activities, modeling tfMRI data is hard and challenging. Previously proposed data-modeling methods including Independent Component Analysis (ICA) and Sparse Dictionary Learning only provided a weakly established model based on blind source separation under the strong assumption that original fMRI signals could be linearly decomposed into time series components with corresponding spatial maps. Meanwhile, analyzing and learning a large amount of tfMRI data from a variety of subjects has been shown to be very demanding but yet challenging even with technological advances in computational hardware. Given the Convolutional Neural Network (CNN), a robust method for learning high-level abstractions from low-level data such as tfMRI time series, in this work we propose a fast and scalable novel framework for distributed deep Convolutional Autoencoder model. This model aims to both learn the complex hierarchical structure of the tfMRI data and to leverage the processing power of multiple GPUs in a distributed fashion. To implement such a model, we have created an enhanced processing pipeline on the top of Apache Spark and Tensorflow library, leveraging from a very large cluster of GPU machines. Experimental data from applying the model on the Human Connectome Project (HCP) show that the proposed model is efficient and scalable toward tfMRI big data analytics, thus enabling data-driven extraction of hierarchical neuroscientific information from massive fMRI big data in the future.\"                                                                                                                                \n",
       " \"Treadmill walking is a convenient tool for studying the human gait; however, a common gait parameter, stride length, can be difficult to calculate directly because relevant reference points continually move backwards. Although there is no direct calculation of stride length itself, we can use positional heel-marker data to directly determine a similar parameter, step length, and we can sum two step lengths to result in one stride length. This proposed method of calculation is simple but seems to be unexplored in other literature, so this paper displays the details of the calculation. Our experimental results differed from the expected values by 2.2% and had a very low standard deviation, suggesting that this method is viable for practical use. The ability to calculate stride length for treadmill walking using heel-marker data may allow for quick and accurate gait calculations that further contribute to the versatility of heel data as a tool for gait analysis.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       " \"We formulate the computational processes of perception in the framework of the principle of least action by postulating the theoretical action being time-integral of the free energy in the brain sciences. The free energy principle is accordingly rephrased as that for autopoietic reasons all viable organisms attempt to minimize the sensory uncertainty about the unpredictable environment over a temporal horizon. By varying the informational action, we derive the brain's recognition dynamics which conducts the adaptive inference of the external causes of sensory data with addressing only canonical positions and momenta of the brain's representations of the dynamical world. To manifest the utility of our theory, we provide how the neural computation may be implemented biophysically at a single-cell level and subsequently be scaled up to a large-scale functional architecture of the brain. We also present formal solutions to the recognition dynamics for a model brain in linear regime and analyze the perceptual trajectories about fixed points in state space.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       " \"Nonrapid eye movement (NREM) sleep desaturation may cause neuronal damage due to the withdrawal of cerebrovascular reactivity. The current study (1) assessed the prevalence of NREM sleep desaturation in nonhypoxemic patients with chronic obstructive pulmonary disease (COPD) and (2) compared a biological marker of cerebral lesion and neuromuscular function in patients with and without NREM sleep desaturation.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       " \"We recorded high-density EEG in a flanker task experiment (31 subjects) and an online BCI control paradigm (4 subjects). On these datasets, we evaluated the use of transfer learning for error decoding with deep convolutional neural networks (deep ConvNets). In comparison with a regularized linear discriminant analysis (rLDA) classifier, ConvNets were significantly better in both intra- and inter-subject decoding, achieving an average accuracy of 84.1 % within subject and 81.7 % on unknown subjects (flanker task). Neither method was, however, able to generalize reliably between paradigms. Visualization of features the ConvNets learned from the data showed plausible patterns of brain activity, revealing both similarities and differences between the different kinds of errors. Our findings indicate that deep learning techniques are useful to infer information about the correctness of action in BCI applications, particularly for the transfer of pre-trained classifiers to new recording sessions or subjects.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       " \"Efficient search acts as a strong selective force in biological systems ranging from cellular populations to predator-prey systems. The search processes commonly involve finding a stationary or mobile target within a heterogeneously structured environment where obstacles limit migration. An open generic question is whether random or directionally biased motions or a combination of both provide an optimal search efficiency and how that depends on the motility and density of targets and obstacles. To address this question, we develop a simple model that involves a random walker searching for its targets in a heterogeneous medium of bond percolation square lattice and used mean first passage time (MFPT, \\$\\\\langle T \\\\rangle\\$) as an indication of average search time. Our analysis reveals a dual effect of directional bias on the minimum value of \\$\\\\langle T \\\\rangle\\$. For a homogeneous medium, directionality always decreases \\$\\\\langle T \\\\rangle\\$ and a pure directional migration (a ballistic motion) serves as the optimized strategy; while for a heterogeneous environment, we find that the optimized strategy involves a combination of directed and random migrations. The relative contribution of these modes is determined by the density of obstacles and motility of targets. Existence of randomness and motility of targets add to the efficiency of search. Our study reveals generic and simple rules that govern search efficiency. Our findings might find application in a number of areas including immunology, cell biology, and ecology.\"                                                                                                                                                                                                                                                                                                                                         \n",
       " \"With the help of a mathematical model, the metabolic process of the Krebs cycle is studied. The autocatalytic processes resulting in both the formation of the self-organization in the Krebs cycle and the appearance of a cyclicity of its dynamics are determined. Some structural-functional connections creating the synchronism of an autoperiodic functioning at the transport in the respiratory chain and the oxidative phosphorylation are investigated. The conditions for breaking the synchronization of processes, increasing the multiplicity of a cyclicity, and for the appearance of chaotic modes are analyzed. The phase-parametric diagram of a cascade of bifurcations showing the transition to a chaotic mode by the Feigenbaum scenario is obtained. The fractal nature of the revealed cascade of bifurcations is demonstrated. The strange attractors formed as a result of the folding are obtained. The results obtained give the idea of structural-functional connections, due to which the self-organization appears in the metabolic process running in a cell. The constructed mathematical model can be applied to the study of the toxic and allergic effects of drugs and various substances on the metabolism of a cell.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       " \"Persistence of motion is the tendency of an object to maintain motion in a direction for short time scales without necessarily being biased in any direction in the long term. One of the most appropriate mathematical tools to study this behaviour and its implications at multiple scales in a multiple-agent system is the velocity-jump process. In the absence of agent-agent interaction, the system can be described at the population level using the hyperbolic telegraph equation. When agent-agent interaction is included, a strictly advective system of partial differential equations (PDEs) has been derived. However, no diffusive limit has been obtained from such a model. A diffusive macroscopic description is desirable, since it allows the exploration of a wider range of scenarios and establishes a direct connection with commonly used statistical tools of movement analysis.We study a generalisation of the velocity-jump process on a two-dimensional lattice with three forms of agent interaction. This generalisation allows us to take a diffusive limit and obtain a faithful macroscopic description. We investigate the properties of the model and we elucidate some of the key characteristic features of interacting persistent agents. In particular, we show an intrinsic anisotropy of the model and we find evidence of a spontaneous form of aggregation at both the micro- and macro-scales.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       " \"We investigate with computer simulations the critical radius of pores in a lipid bilayer membrane. Ilton et al. (2016) recently showed that nucleated pores in a homopolymer film can increase or decrease in size, depending on whether they are larger or smaller than a critical size which scales linearly with film thickness. Using dissipative particle dynamics, a particle-based simulation method, we investigate the same scenario for a lipid bilayer membrane whose structure is determined by lipid-water interactions. We simulate a perforated membrane in which holes larger than a critical radius grow, while holes smaller than the critical radius close, as in the experiment of Ilton et al. (2016). By altering system parameters such as the number of particles per lipid and the periodicity, we also describe scenarios in which pores of any initial size can seal or even remain stable, showing a fundamental difference in the behavior of lipid membranes from polymer films.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       " \"Post-translational modification (PTM) of proteins plays a key role in signal transduction, and hence significant effort has gone toward understanding how PTM networks process information. This involves, on the theory side, analyzing the dynamical systems arising from such networks. Which networks are, for instance, bistable? Which networks admit sustained oscillations? Which parameter values enable such behaviors? In this Perspective, we highlight recent progress in this area and point out some important future directions. Along the way, we summarize several techniques for analyzing general networks, such as eliminating variables to obtain steady-state parametrizations, and harnessing results on how incorporating intermediates affects dynamics.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       " \"Until recently, much of the microbial world was hidden from view. A global research effort has changed this, unveiling and quantifying microbial diversity across enormous range of critically-important contexts, from the human microbiome, to plant-soil interactions, to marine life. Yet what has remained largely hidden is the interplay of ecological and evolutionary processes that led to the diversity we observe in the present day. We introduce a theoretical framework to quantify the effect of ecological innovations in microbial evolutionary history, using a new, coarse-grained approach that is robust to the incompleteness and ambiguities in microbial community data. Applying this methodology, we identify a balance of gradual, ongoing diversification and rapid bursts across a vast range of microbial habitats. Moreover, we find universal quantitative similarities in the tempo of diversification, independent of habitat type.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       " \"The goal of this paper is to advance an extensible theory of living systems using an approach to biomathematics and biocomputation that suitably addresses self-organized, self-referential and anticipatory systems with multi-temporal multi-agents. Our first step is to provide foundations for modelling of emergent and evolving dynamic multi-level organic complexes and their sustentative processes in artificial and natural life systems. Main applications are in life sciences, medicine, ecology and astrobiology, as well as robotics, industrial automation and man-machine interface. Since 2011 over 100 scientists from a number of disciplines have been exploring a substantial set of theoretical frameworks for a comprehensive theory of life known as Integral Biomathics. That effort identified the need for a robust core model of organisms as dynamic wholes, using advanced and adequately computable mathematics. The work described here for that core combines the advantages of a situation and context aware multivalent computational logic for active self-organizing networks, Wandering Logic Intelligence (WLI), and a multi-scale dynamic category theory, Memory Evolutive Systems (MES), hence WLIMES. This is presented to the modeller via a formal augmented reality language as a first step towards practical modelling and simulation of multi-level living systems. Initial work focuses on the design and implementation of this visual language and calculus (VLC) and its graphical user interface. The results will be integrated within the current methodology and practices of theoretical biology and (personalized) medicine to deepen and to enhance the holistic understanding of life. \"                                                                                                                                                                                                 "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = datadict[\"abstracts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6761"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <azure.storage.blob.models.Blob object at 0x7f8e54c5a198>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fblob = bbs[:get_blob_to_path](\"algorithmiagensim\", \"topicdict\", file_path=\"/home/jovyan/topicdict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IOStream(<file /home/jovyan/topicdict>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"/home/jovyan/topicdict\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %14.2 %>                            ]  28.4 % [==================>                      ]  42.7 %]  56.8 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===========================>             ]  66.9 %       ]  81.0 % [=======================================> ]  95.2 %.2 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      " \u001b[90m [682c06a0]\u001b[39m\u001b[92m + JSON v0.20.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = read(f, String);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 142 entries:\n",
       "  \"nlin.SI\"            => \"math\"\n",
       "  \"gr-qc\"              => \"Physics\"\n",
       "  \"q-fin.ST\"           => \"finance\"\n",
       "  \"cs.LO\"              => \"compsci\"\n",
       "  \"stat.OT\"            => \"math\"\n",
       "  \"astro-ph.IM\"        => \"Physics\"\n",
       "  \"q-fin.MF\"           => \"finance\"\n",
       "  \"hep-th\"             => \"Physics\"\n",
       "  \"stat.ML\"            => \"compsci\"\n",
       "  \"physics.data-an\"    => \"Physics\"\n",
       "  \"physics.hist-ph\"    => \"Physics\"\n",
       "  \"cs.DL\"              => \"compsci\"\n",
       "  \"physics.bio-ph\"     => \"Physics\"\n",
       "  \"physics.ao-ph\"      => \"Physics\"\n",
       "  \"math.KT\"            => \"math\"\n",
       "  \"cond-mat.str-el\"    => \"Physics\"\n",
       "  \"cs.IT\"              => \"compsci\"\n",
       "  \"physics.acc-ph\"     => \"Physics\"\n",
       "  \"math.DS\"            => \"math\"\n",
       "  \"physics.geo-ph\"     => \"Physics\"\n",
       "  \"q-fin.RM\"           => \"finance\"\n",
       "  \"cs.HC\"              => \"compsci\"\n",
       "  \"cs.IR\"              => \"compsci\"\n",
       "  \"cs.SE\"              => \"compsci\"\n",
       "  \"cond-mat.quant-gas\" => \"Physics\"\n",
       "  ⋮                    => ⋮"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicdict = JSON.parse(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: tokenize not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: tokenize not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[28]:1"
     ]
    }
   ],
   "source": [
    "tokenize(datadict[\"abstracts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Deep convolutional neural networks (CNN) have recently been shown in many computer vision and pattern recog- nition applications to outperform by a significant margin state- of-the-art solutions that use traditional hand-crafted features. However, this impressive performance is yet to be fully exploited in robotics. In this paper, we focus one specific problem that can benefit from the recent development of the CNN technology, i.e., we focus on using a pre-trained CNN model as a method of generating an image representation appropriate for visual loop closure detection in SLAM (simultaneous localization and mapping). We perform a comprehensive evaluation of the outputs at the intermediate layers of a CNN as image descriptors, in comparison with state-of-the-art image descriptors, in terms of their ability to match images for detecting loop closures. The main conclusions of our study include: (a) CNN-based image representations perform comparably to state-of-the-art hand- crafted competitors in environments without significant lighting change, (b) they outperform state-of-the-art competitors when lighting changes significantly, and (c) they are also significantly faster to extract than the state-of-the-art hand-crafted features even on a conventional CPU and are two orders of magnitude faster on an entry-level GPU.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = datadict[\"abstracts\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191-element Array{SubString{String},1}:\n",
       " \"Deep\"         \n",
       " \"convolutional\"\n",
       " \"neural\"       \n",
       " \"networks\"     \n",
       " \"(CNN)\"        \n",
       " \"have\"         \n",
       " \"recently\"     \n",
       " \"been\"         \n",
       " \"shown\"        \n",
       " \"in\"           \n",
       " \"many\"         \n",
       " \"computer\"     \n",
       " \"vision\"       \n",
       " ⋮              \n",
       " \"CPU\"          \n",
       " \"and\"          \n",
       " \"are\"          \n",
       " \"two\"          \n",
       " \"orders\"       \n",
       " \"of\"           \n",
       " \"magnitude\"    \n",
       " \"faster\"       \n",
       " \"on\"           \n",
       " \"an\"           \n",
       " \"entry-level\"  \n",
       " \"GPU.\"         "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 0 entries"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcounts = Dict{String,Int64}()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in datadict[\"abstracts\"]\n",
    "    wordlist = split(l)\n",
    "    for word in wordlist\n",
    "        wordcounts[word]=get(wordcounts, word, 0) + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77384"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(wordcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 77384 entries:\n",
       "  \"T-forward\"              => 1\n",
       "  \"rearrangement\"          => 3\n",
       "  \"semiperfect\"            => 1\n",
       "  \"(SNIa)\"                 => 1\n",
       "  \"\\$O(\\\\epsilon)\\$-close\" => 1\n",
       "  \"titration\"              => 3\n",
       "  \"photosynthesis\"         => 1\n",
       "  \"inhomogeneities.\"       => 5\n",
       "  \"Topological\"            => 4\n",
       "  \"(1986)\"                 => 1\n",
       "  \"(JDFT)\"                 => 1\n",
       "  \"\\$n\\$-space.\"           => 1\n",
       "  \"\\$\\\\Lambda\\\\lesssim1\\$\" => 1\n",
       "  \"anaerobic\"              => 4\n",
       "  \"(IGC)\"                  => 1\n",
       "  \"cost-benefit\"           => 2\n",
       "  \"valuation.\"             => 1\n",
       "  \"gathered\"               => 5\n",
       "  \"Core\"                   => 2\n",
       "  \"\\$v\\$\"                  => 17\n",
       "  \"persists:\"              => 1\n",
       "  \"X-band\"                 => 1\n",
       "  \"Circulating\"            => 1\n",
       "  \"sobre\"                  => 2\n",
       "  \"underground\"            => 5\n",
       "  ⋮                        => ⋮"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77384-element Array{Pair{String,Int64},1}:\n",
       "                                      \"the\" => 66397\n",
       "                                       \"of\" => 45804\n",
       "                                      \"and\" => 26122\n",
       "                                        \"a\" => 25151\n",
       "                                       \"to\" => 20687\n",
       "                                       \"in\" => 18316\n",
       "                                       \"is\" => 14411\n",
       "                                     \"that\" => 11725\n",
       "                                      \"for\" => 11074\n",
       "                                     \"with\" => 9169 \n",
       "                                       \"We\" => 8739 \n",
       "                                       \"we\" => 7613 \n",
       "                                       \"on\" => 7211 \n",
       "                                            ⋮       \n",
       "                                    \"(EMD)\" => 1    \n",
       "                                 \"Dihedral\" => 1    \n",
       " \"(7.7\\\\pm3.4)\\\\times10^{14}\\\\,M_\\\\odot\\$,\" => 1    \n",
       "                              \"morphotypes\" => 1    \n",
       "                              \"linguistics\" => 1    \n",
       "                                 \"\\\\texttt\" => 1    \n",
       "                                  \"shorten\" => 1    \n",
       "                                 \"option's\" => 1    \n",
       "                                      \"TPs\" => 1    \n",
       "                                  \"forces:\" => 1    \n",
       "                                 \"(Science\" => 1    \n",
       "                             \"instantiated\" => 1    "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedworddic = sort(collect(wordcounts), by = tuple -> last(tuple), rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77336-element Array{Pair{String,Int64},1}:\n",
       "                                   \"method\" => 1375\n",
       "                                    \"based\" => 1362\n",
       "                                   \"number\" => 1325\n",
       "                                  \"present\" => 1303\n",
       "                                     \"both\" => 1297\n",
       "                                     \"time\" => 1286\n",
       "                                     \"find\" => 1285\n",
       "                                \"different\" => 1280\n",
       "                                    \"field\" => 1275\n",
       "                                    \"where\" => 1268\n",
       "                                      \"one\" => 1257\n",
       "                                     \"more\" => 1232\n",
       "                                     \"when\" => 1216\n",
       "                                            ⋮      \n",
       "                                    \"(EMD)\" => 1   \n",
       "                                 \"Dihedral\" => 1   \n",
       " \"(7.7\\\\pm3.4)\\\\times10^{14}\\\\,M_\\\\odot\\$,\" => 1   \n",
       "                              \"morphotypes\" => 1   \n",
       "                              \"linguistics\" => 1   \n",
       "                                 \"\\\\texttt\" => 1   \n",
       "                                  \"shorten\" => 1   \n",
       "                                 \"option's\" => 1   \n",
       "                                      \"TPs\" => 1   \n",
       "                                  \"forces:\" => 1   \n",
       "                                 \"(Science\" => 1   \n",
       "                             \"instantiated\" => 1   "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortwl = sortedworddic[49:77384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Array{String, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for i in 1:length(shortwl)\n",
    "    if shortwl[i][2]> 1\n",
    "        n = i\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31349"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31349-element Array{Pair{String,Int64},1}:\n",
       "          \"method\" => 1375\n",
       "           \"based\" => 1362\n",
       "          \"number\" => 1325\n",
       "         \"present\" => 1303\n",
       "            \"both\" => 1297\n",
       "            \"time\" => 1286\n",
       "            \"find\" => 1285\n",
       "       \"different\" => 1280\n",
       "           \"field\" => 1275\n",
       "           \"where\" => 1268\n",
       "             \"one\" => 1257\n",
       "            \"more\" => 1232\n",
       "            \"when\" => 1216\n",
       "                   ⋮      \n",
       "            \"akin\" => 2   \n",
       "        \"painting\" => 2   \n",
       "        \"hot-star\" => 2   \n",
       "       \"breaking,\" => 2   \n",
       "        \"scoring,\" => 2   \n",
       "       \"\\\\nu_\\\\mu\" => 2   \n",
       "  \"anticorrelated\" => 2   \n",
       " \"trial-and-error\" => 2   \n",
       "   \"inferentially\" => 2   \n",
       "    \"retardation.\" => 2   \n",
       "       \"outflows,\" => 2   \n",
       "         \"\\$St\\$,\" => 2   "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortwl = shortwl[1:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31349"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(shortwl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words =  Array{String, 1}(undef,length(shortwl) )\n",
    "for i in 1:length(shortwl)\n",
    "   words[i] =shortwl[i][1]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 0 entries"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordloc = dict = Dict{String,Int64}()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,w) in enumerate(words)\n",
    "    wordloc[w] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "KeyError: key \"foo\" not found",
     "output_type": "error",
     "traceback": [
      "KeyError: key \"foo\" not found",
      "",
      "Stacktrace:",
      " [1] getindex(::Dict{String,Int64}, ::String) at ./dict.jl:478",
      " [2] top-level scope at In[47]:1"
     ]
    }
   ],
   "source": [
    "wordloc[\"foo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docvec (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function docvec(doc)\n",
    "    vec = zeros(Int64, length(words))\n",
    "    docwords = split(doc)\n",
    "    for w in docwords\n",
    "        x = get(wordloc, w, 0)\n",
    "        if x > 0\n",
    "            vec[x] += 1\n",
    "        end\n",
    "    end\n",
    "    return vec\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict[\"abstracts\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they 2 significant 2 image 4 perform 2 focus 2 state-of-the-art 4 faster 2 loop 2 outperform 2 CNN 3 hand-crafted 2 competitors 2 lighting 2 descriptors, 2 "
     ]
    }
   ],
   "source": [
    "dv = docvec(datadict[\"abstracts\"][1])\n",
    "for i in 1:length(words)\n",
    "    if dv[i] > 1\n",
    "        print(words[i], \" \", string(dv[i]),\" \")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Convolutional Neural Network-Based Image Representation for Visual Loop   Closure Detection [cs.RO]\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict[\"titles\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: azure.storage is not a valid module variable name, use @pyimport azure.storage as <name>",
     "output_type": "error",
     "traceback": [
      "ArgumentError: azure.storage is not a valid module variable name, use @pyimport azure.storage as <name>",
      "",
      "Stacktrace:",
      " [1] pyimport_name(::Expr, ::Tuple{}) at /home/dbgannon/.julia/packages/PyCall/0jMpb/src/PyCall.jl:520",
      " [2] @pyimport(::LineNumberNode, ::Module, ::Any, ::Vararg{Any,N} where N) at /home/dbgannon/.julia/packages/PyCall/0jMpb/src/PyCall.jl:526"
     ]
    }
   ],
   "source": [
    "@pyimport azure.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <azure.cosmosdb.table.tableservice.TableService object at 0x7f6f3b955e48>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport azure.cosmosdb.table as aztable\n",
    "bbs = aztable.TableService(\"dbgannonstorage\", \"h+f50obgDsfiAk5XT6I8W2Da4egkjsLpidXn0D8QYXePts6icTTO9Cf91RLtKHZ8Ar2fFdkiRHo/+rkk61b1BQ==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"PartitionKey\" => \"fromhome\"\n",
       "  \"etag\"         => \"W/\\\"datetime'2018-11-18T19%3A29%3A16.0753414Z'\\\"\"\n",
       "  \"worker\"       => \"0\"\n",
       "  \"RowKey\"       => \"1\"\n",
       "  \"Timestamp\"    => 2018-11-18T19:29:16.075"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs[:get_entity](\"datafromjulia\", \"fromhome\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 0 entries"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = Dict{Any,Any}()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"33\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[\"PartitionKey\"]= \"fromhome\"\n",
    "item[\"RowKey\"]=\"2\"\n",
    "item[\"worker\"]= \"33\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"W/\\\"datetime'2018-11-19T00%3A48%3A18.1082163Z'\\\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs[:insert_entity](\"datafromjulia\",item )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "putInTable (generic function with 1 method)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function putInTable(table, row, data)\n",
    "    item = Dict{Any,Any}()\n",
    "    item[\"PartitionKey\"]= string(\"Node_\",string(myid()))\n",
    "    item[\"RowKey\"] = string(row)\n",
    "    item[\"thedata\"] = data\n",
    "    table[:insert_entity](\"datafromjulia\", item)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"W/\\\"datetime'2018-11-19T01%3A08%3A36.257265Z'\\\"\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "putInTable(bbs, 1, \"foobar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
